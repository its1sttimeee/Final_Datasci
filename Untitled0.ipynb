{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "project_folder = 'D:\\Jakkaf1rst\\Final_Datasci'"
      ],
      "metadata": {
        "id": "8U3oBpdixh5V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60464c66-18ff-4f33-e294-711ccf976cc1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:2: SyntaxWarning: invalid escape sequence '\\J'\n",
            "<>:2: SyntaxWarning: invalid escape sequence '\\J'\n",
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_32540\\348495626.py:2: SyntaxWarning: invalid escape sequence '\\J'\n",
            "  project_folder = 'D:\\Jakkaf1rst\\Final_Datasci'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(project_folder)"
      ],
      "metadata": {
        "id": "fXJi5uSbxj9m"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = 'balanced_metadata.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LaXypL40xlum",
        "outputId": "0e6bdb37-22f1-4896-9b80-bb3c6a9a1396"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           filename  \\\n",
              "0  cv-valid-train/sample-000005.mp3   \n",
              "1  cv-valid-train/sample-000008.mp3   \n",
              "2  cv-valid-train/sample-000013.mp3   \n",
              "3  cv-valid-train/sample-000023.mp3   \n",
              "4  cv-valid-train/sample-000034.mp3   \n",
              "\n",
              "                                                text        age  gender accent  \n",
              "0  a shepherd may like to travel but he should ne...   twenties  female     us  \n",
              "1                      put jackie right on the staff  seventies    male     us  \n",
              "2  but he had found a guide and didn't want to mi...   thirties  female     us  \n",
              "3    i had seen all that it would presently bring me   thirties    male     us  \n",
              "4            i have had the same dream twice he said   fourties  female     us  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>text</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>accent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cv-valid-train/sample-000005.mp3</td>\n",
              "      <td>a shepherd may like to travel but he should ne...</td>\n",
              "      <td>twenties</td>\n",
              "      <td>female</td>\n",
              "      <td>us</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cv-valid-train/sample-000008.mp3</td>\n",
              "      <td>put jackie right on the staff</td>\n",
              "      <td>seventies</td>\n",
              "      <td>male</td>\n",
              "      <td>us</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cv-valid-train/sample-000013.mp3</td>\n",
              "      <td>but he had found a guide and didn't want to mi...</td>\n",
              "      <td>thirties</td>\n",
              "      <td>female</td>\n",
              "      <td>us</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cv-valid-train/sample-000023.mp3</td>\n",
              "      <td>i had seen all that it would presently bring me</td>\n",
              "      <td>thirties</td>\n",
              "      <td>male</td>\n",
              "      <td>us</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cv-valid-train/sample-000034.mp3</td>\n",
              "      <td>i have had the same dream twice he said</td>\n",
              "      <td>fourties</td>\n",
              "      <td>female</td>\n",
              "      <td>us</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlaqtTUYy8Xj",
        "outputId": "8595b52f-9949-4d7c-8f14-040ff2aff876"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26362, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Add Thai Data In  Dataframe"
      ],
      "metadata": {
        "id": "C9LtQqPnxvf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thai_sound = 'file_data_science_final.csv'\n",
        "df_thai = pd.read_csv(thai_sound)\n",
        "df_thai.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6KMhRYyxx3e5",
        "outputId": "cf54ca9e-17f9-4bfa-b375-5472da0db0f4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      filename                   text  age  gender    accent\n",
              "0  cv-valid-train/01_Pukao.mp3             I love cat   22  female  Thailand\n",
              "1  cv-valid-train/02_Pukao.mp3             I love dog   19    male  Thailand\n",
              "2  cv-valid-train/03_Pukao.mp3        I play football   21  female  Thailand\n",
              "3  cv-valid-train/04_Pukao.mp3  nice to see you again   25  female  Thailand\n",
              "4  cv-valid-train/05_Pukao.mp3    where have you been   23  female  Thailand"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>text</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>accent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cv-valid-train/01_Pukao.mp3</td>\n",
              "      <td>I love cat</td>\n",
              "      <td>22</td>\n",
              "      <td>female</td>\n",
              "      <td>Thailand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cv-valid-train/02_Pukao.mp3</td>\n",
              "      <td>I love dog</td>\n",
              "      <td>19</td>\n",
              "      <td>male</td>\n",
              "      <td>Thailand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cv-valid-train/03_Pukao.mp3</td>\n",
              "      <td>I play football</td>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>Thailand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cv-valid-train/04_Pukao.mp3</td>\n",
              "      <td>nice to see you again</td>\n",
              "      <td>25</td>\n",
              "      <td>female</td>\n",
              "      <td>Thailand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cv-valid-train/05_Pukao.mp3</td>\n",
              "      <td>where have you been</td>\n",
              "      <td>23</td>\n",
              "      <td>female</td>\n",
              "      <td>Thailand</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>‡πÅ‡∏õ‡∏•‡∏á Age ‡∏à‡∏≤‡∏Å‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠"
      ],
      "metadata": {
        "id": "opva2hefyiL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def age_to_group(age):\n",
        "    if pd.isnull(age):\n",
        "        return None\n",
        "    elif 10 <= age < 20:\n",
        "        return 'teens'\n",
        "    elif 20 <= age < 30:\n",
        "        return 'twenties'\n",
        "    elif 30 <= age < 40:\n",
        "        return 'thirties'\n",
        "    elif 40 <= age < 50:\n",
        "        return 'fourties'\n",
        "    elif 50 <= age < 60:\n",
        "        return 'fifties'\n",
        "    elif 60 <= age < 70:\n",
        "        return 'sixties'\n",
        "    elif 70 <= age < 80:\n",
        "        return 'seventies'\n",
        "    elif 80 <= age < 90:\n",
        "        return 'eighties'\n",
        "    else:\n",
        "        return 'other'\n",
        "\n",
        "# ‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå age\n",
        "df_thai['age'] = df_thai['age'].apply(age_to_group)\n",
        "df_thai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "collapsed": true,
        "id": "BxbBVdKmyMcs",
        "outputId": "740018f9-0efe-4229-8320-9d869f257268"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        filename                     text       age  gender  \\\n",
              "0    cv-valid-train/01_Pukao.mp3               I love cat  twenties  female   \n",
              "1    cv-valid-train/02_Pukao.mp3               I love dog     teens    male   \n",
              "2    cv-valid-train/03_Pukao.mp3          I play football  twenties  female   \n",
              "3    cv-valid-train/04_Pukao.mp3    nice to see you again  twenties  female   \n",
              "4    cv-valid-train/05_Pukao.mp3      where have you been  twenties  female   \n",
              "..                           ...                      ...       ...     ...   \n",
              "149  cv-valid-train/48_Japan.mp3     you flirting with me  twenties    male   \n",
              "150  cv-valid-train/49_Japan.mp3       i love your energy  twenties    male   \n",
              "151  cv-valid-train/50_Japan.mp3       can i take you out  twenties    male   \n",
              "152  cv-valid-train/51_Japan.mp3         i think we click  twenties    male   \n",
              "153  cv-valid-train/52_Japan.mp3  not much going on today  twenties    male   \n",
              "\n",
              "       accent  \n",
              "0    Thailand  \n",
              "1    Thailand  \n",
              "2    Thailand  \n",
              "3    Thailand  \n",
              "4    Thailand  \n",
              "..        ...  \n",
              "149  Thailand  \n",
              "150  Thailand  \n",
              "151  Thailand  \n",
              "152  Thailand  \n",
              "153  Thailand  \n",
              "\n",
              "[154 rows x 5 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>text</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>accent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cv-valid-train/01_Pukao.mp3</td>\n",
              "      <td>I love cat</td>\n",
              "      <td>twenties</td>\n",
              "      <td>female</td>\n",
              "      <td>Thailand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cv-valid-train/02_Pukao.mp3</td>\n",
              "      <td>I love dog</td>\n",
              "      <td>teens</td>\n",
              "      <td>male</td>\n",
              "      <td>Thailand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cv-valid-train/03_Pukao.mp3</td>\n",
              "      <td>I play football</td>\n",
              "      <td>twenties</td>\n",
              "      <td>female</td>\n",
              "      <td>Thailand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cv-valid-train/04_Pukao.mp3</td>\n",
              "      <td>nice to see you again</td>\n",
              "      <td>twenties</td>\n",
              "      <td>female</td>\n",
              "      <td>Thailand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cv-valid-train/05_Pukao.mp3</td>\n",
              "      <td>where have you been</td>\n",
              "      <td>twenties</td>\n",
              "      <td>female</td>\n",
              "      <td>Thailand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>cv-valid-train/48_Japan.mp3</td>\n",
              "      <td>you flirting with me</td>\n",
              "      <td>twenties</td>\n",
              "      <td>male</td>\n",
              "      <td>Thailand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>cv-valid-train/49_Japan.mp3</td>\n",
              "      <td>i love your energy</td>\n",
              "      <td>twenties</td>\n",
              "      <td>male</td>\n",
              "      <td>Thailand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>cv-valid-train/50_Japan.mp3</td>\n",
              "      <td>can i take you out</td>\n",
              "      <td>twenties</td>\n",
              "      <td>male</td>\n",
              "      <td>Thailand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>cv-valid-train/51_Japan.mp3</td>\n",
              "      <td>i think we click</td>\n",
              "      <td>twenties</td>\n",
              "      <td>male</td>\n",
              "      <td>Thailand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>cv-valid-train/52_Japan.mp3</td>\n",
              "      <td>not much going on today</td>\n",
              "      <td>twenties</td>\n",
              "      <td>male</td>\n",
              "      <td>Thailand</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>154 rows √ó 5 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Combind CSV File"
      ],
      "metadata": {
        "id": "d64lTnAMzUfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.concat([df, df_thai], ignore_index=True)\n",
        "print(df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UH0aXBMy2Dv",
        "outputId": "a14e996d-d581-409a-b071-8094cb88f6ec"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(26516, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Test2"
      ],
      "metadata": {
        "id": "Ke07KvyJC5VR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á progress bar"
      ],
      "metadata": {
        "id": "ZX9wY6pTC711"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° list ‡πÄ‡∏Å‡πá‡∏ö feature ‡πÅ‡∏•‡∏∞ label\n",
        "mfcc_features = []\n",
        "labels = []\n",
        "\n",
        "# ‡πÉ‡∏ä‡πâ tqdm ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á progress\n",
        "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    file_path = row['filename']\n",
        "    accent_label = row['accent']\n",
        "    try:\n",
        "        # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô MFCC ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢\n",
        "        y, sr = librosa.load(file_path, sr=None)\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "        mfcc_mean = np.mean(mfcc.T, axis=0)\n",
        "\n",
        "        mfcc_features.append(mfcc_mean)\n",
        "        labels.append(accent_label)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_path}: {e}\")\n",
        "\n",
        "# ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô array\n",
        "X = np.array(mfcc_features)\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(labels)\n",
        "\n",
        "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö shape\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "print(\"Classes:\", le.classes_)\n",
        "\n",
        "# üîΩ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å X ‡πÅ‡∏•‡∏∞ y ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≠\n",
        "np.save('X_mfcc.npy', X)\n",
        "np.save('y_labels.npy', y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfkX6PDRC9S6",
        "outputId": "a108d5f1-acb8-44cc-c503-4aa9ecb58e36"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26516/26516 [18:03<00:00, 24.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (26516, 13)\n",
            "y shape: (26516,)\n",
            "Classes: ['Thailand' 'african' 'australia' 'bermuda' 'canada' 'england' 'hongkong'\n",
            " 'indian' 'ireland' 'malaysia' 'newzealand' 'philippines' 'scotland'\n",
            " 'singapore' 'southatlandtic' 'us' 'wales']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.load('X_mfcc.npy')\n",
        "y = np.load('y_labels.npy')"
      ],
      "metadata": {
        "id": "plhMgzCHJGyJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rEy_oX1Jau9",
        "outputId": "20004803-2531-447d-89ef-c01014b77104"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                precision    recall  f1-score   support\n",
            "\n",
            "      Thailand       1.00      0.48      0.65        23\n",
            "       african       0.93      0.63      0.75       213\n",
            "     australia       0.69      0.80      0.74       803\n",
            "       bermuda       1.00      0.57      0.72        30\n",
            "        canada       0.72      0.73      0.72       752\n",
            "       england       0.59      0.66      0.63       794\n",
            "      hongkong       1.00      0.52      0.69        21\n",
            "        indian       0.64      0.81      0.72       899\n",
            "       ireland       0.90      0.60      0.72       185\n",
            "      malaysia       1.00      0.45      0.62        38\n",
            "    newzealand       0.92      0.74      0.82       229\n",
            "   philippines       0.93      0.39      0.55        69\n",
            "      scotland       0.93      0.69      0.79       331\n",
            "     singapore       1.00      0.47      0.64        30\n",
            "southatlandtic       0.83      0.28      0.42        18\n",
            "            us       0.57      0.53      0.55       818\n",
            "         wales       0.96      0.51      0.67        51\n",
            "\n",
            "      accuracy                           0.69      5304\n",
            "     macro avg       0.86      0.58      0.67      5304\n",
            "  weighted avg       0.71      0.69      0.69      5304\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# One-hot encoding labels (‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÄ‡∏õ‡πá‡∏ô multi-class classification)\n",
        "num_classes = len(np.unique(y))\n",
        "y_train_cat = to_categorical(y_train, num_classes)\n",
        "y_test_cat = to_categorical(y_test, num_classes)\n"
      ],
      "metadata": {
        "id": "-3HaBczwNsHF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a-6zhmyqOvmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test"
      ],
      "metadata": {
        "id": "Az5_2YWs1ovk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "base_path = 'cv-valid-train'\n",
        "\n",
        "features_audio = []\n",
        "features_text = []\n",
        "features_age = []\n",
        "features_gender = []\n",
        "labels = []\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    file_path = row['filename']\n",
        "\n",
        "    try:\n",
        "        y, sr = librosa.load(file_path, sr=16000)\n",
        "        y = y[:3*sr] if len(y) > 3*sr else np.pad(y, (0, 3*sr - len(y)))\n",
        "\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13).T\n",
        "        mfcc_flat = mfcc.flatten()\n",
        "        features_audio.append(mfcc_flat)\n",
        "\n",
        "        features_text.append(row['text'])\n",
        "        features_age.append(row['age'])\n",
        "        features_gender.append(row['gender'])\n",
        "        labels.append(row['accent'])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error processing {file_path}: {e}\")"
      ],
      "metadata": {
        "id": "TeBHqPJd1qXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=100)\n",
        "X_text = vectorizer.fit_transform(features_text).toarray()\n",
        "\n",
        "# ‡πÅ‡∏õ‡∏•‡∏á‡∏≠‡∏≤‡∏¢‡∏∏‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏®‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç\n",
        "le_age = LabelEncoder()\n",
        "X_age = le_age.fit_transform(features_age).reshape(-1, 1)\n",
        "\n",
        "le_gender = LabelEncoder()\n",
        "X_gender = le_gender.fit_transform(features_gender).reshape(-1, 1)\n",
        "\n",
        "# ‡πÅ‡∏õ‡∏•‡∏á label ‡∏™‡∏≥‡πÄ‡∏ô‡∏µ‡∏¢‡∏á\n",
        "le_label = LabelEncoder()\n",
        "y = le_label.fit_transform(labels)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_audio = np.array(features_audio)\n",
        "scaler = StandardScaler()\n",
        "X_audio_scaled = scaler.fit_transform(X_audio)\n",
        "\n",
        "# ‡∏£‡∏ß‡∏°: ‡πÄ‡∏™‡∏µ‡∏¢‡∏á + ‡∏≠‡∏≤‡∏¢‡∏∏ + ‡πÄ‡∏û‡∏® + ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°\n",
        "X_full = np.hstack([X_audio_scaled, X_age, X_gender, X_text])\n",
        "print(\"Shape of input:\", X_full.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKV_z6MP18_u",
        "outputId": "9ee5e44b-4a09-4144-dd0b-d7ee3c382587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of input: (26516, 1324)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.metrics import classification_report\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X_full, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "# model.fit(X_train, y_train)\n",
        "\n",
        "# y_pred = model.predict(X_test)\n",
        "# print(classification_report(y_test, y_pred, target_names=le_label.classes_))"
      ],
      "metadata": {
        "id": "FxaFlMmY1-kS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier, GradientBoostingClassifier\n",
        ")\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# OPTIONAL: ‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å‡πÉ‡∏ä‡πâ XGBoost\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "    has_xgb = True\n",
        "except ImportError:\n",
        "    has_xgb = False\n",
        "\n",
        "# ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_full, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡πÄ‡∏û‡∏¥‡πà‡∏° n_jobs=-1 ‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö)\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"KNN\": KNeighborsClassifier(n_jobs=-1),\n",
        "    \"SVM\": SVC(),  # ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö n_jobs\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, n_jobs=-1),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "    \"Naive Bayes\": GaussianNB()\n",
        "}\n",
        "\n",
        "# ‡πÉ‡∏ä‡πâ GPU ‡∏Å‡∏±‡∏ö XGBoost ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ\n",
        "if has_xgb:\n",
        "    models[\"XGBoost\"] = XGBClassifier(\n",
        "        use_label_encoder=False,\n",
        "        eval_metric='mlogloss',\n",
        "        tree_method='gpu_hist',        # ‡πÉ‡∏ä‡πâ GPU\n",
        "        predictor='gpu_predictor'\n",
        "    )\n",
        "\n",
        "# ‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏ó‡∏∏‡∏Å‡∏£‡∏∏‡πà‡∏ô\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nüîé Training model: {name}\")\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    print(\"‚úÖ Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"üìä Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "    print(\"üìÑ Classification Report:\\n\", classification_report(y_test, y_pred, target_names=le_label.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H92TRtqX2Kt3",
        "outputId": "ecdc03e1-09c7-4961-9308-5f5fb646c638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîé Training model: Logistic Regression\n",
            "‚úÖ Accuracy: 0.3401206636500754\n",
            "üìä Confusion Matrix:\n",
            " [[ 10   0   1   0   3   1   0   5   0   0   0   0   1   0   0   2   0]\n",
            " [  0  45  24   0  23  27   0  31   9   3   5   7   6   0   0  30   3]\n",
            " [  2  19 339   2  76 114   2  61  27   3  34   3  30   1   0  87   3]\n",
            " [  0   0   1   8   8   4   0   5   1   0   0   0   0   0   0   3   0]\n",
            " [  2  38  99   3 231  85   1  88  10   6  22  13  28   0   2 118   6]\n",
            " [  4  24 118  11  77 203   3  94  31   5  35   7  63   1   0 107  11]\n",
            " [  0   2   5   0   1   3   4   5   0   0   0   0   0   0   0   0   1]\n",
            " [  2  23  44  12  80  61   0 498  15   9  20  22  17   3   2  82   9]\n",
            " [  0   8  17   0  14  31   1  10  69   0   2   2   7   0   0  23   1]\n",
            " [  0   1   5   0   1   5   0   9   0  11   0   1   0   0   1   4   0]\n",
            " [  0   6  30   1  15  35   0   6   7   2  79   4  18   3   0  21   2]\n",
            " [  0   0   2   1  19   6   0  15   3   2   2  11   0   0   0   6   2]\n",
            " [  1   5  32   2  24  60   0  26   5   2   9   3 105   1   1  46   9]\n",
            " [  1   1   2   1   1   2   0   8   2   0   0   4   2   3   0   3   0]\n",
            " [  0   1   0   0   0   4   0   4   0   0   1   0   1   0   6   1   0]\n",
            " [  8  29 108   7 115 132   5 133  26   5  23   7  34   4   2 166  14]\n",
            " [  0   0   6   0   6  11   0   2   1   0   1   0   3   0   0   5  16]]\n",
            "üìÑ Classification Report:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "      Thailand       0.33      0.43      0.38        23\n",
            "       african       0.22      0.21      0.22       213\n",
            "     australia       0.41      0.42      0.41       803\n",
            "       bermuda       0.17      0.27      0.21        30\n",
            "        canada       0.33      0.31      0.32       752\n",
            "       england       0.26      0.26      0.26       794\n",
            "      hongkong       0.25      0.19      0.22        21\n",
            "        indian       0.50      0.55      0.52       899\n",
            "       ireland       0.33      0.37      0.35       185\n",
            "      malaysia       0.23      0.29      0.26        38\n",
            "    newzealand       0.34      0.34      0.34       229\n",
            "   philippines       0.13      0.16      0.14        69\n",
            "      scotland       0.33      0.32      0.33       331\n",
            "     singapore       0.19      0.10      0.13        30\n",
            "southatlandtic       0.43      0.33      0.38        18\n",
            "            us       0.24      0.20      0.22       818\n",
            "         wales       0.21      0.31      0.25        51\n",
            "\n",
            "      accuracy                           0.34      5304\n",
            "     macro avg       0.29      0.30      0.29      5304\n",
            "  weighted avg       0.34      0.34      0.34      5304\n",
            "\n",
            "\n",
            "üîé Training model: KNN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
            "    cpu_info = subprocess.run(\n",
            "        \"wmic CPU Get NumberOfCores /Format:csv\".split(),\n",
            "        capture_output=True,\n",
            "        text=True,\n",
            "    )\n",
            "  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 554, in run\n",
            "    with Popen(*popenargs, **kwargs) as process:\n",
            "         ~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 1039, in __init__\n",
            "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
            "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "                        pass_fds, cwd, env,\n",
            "                        ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "                        gid, gids, uid, umask,\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^\n",
            "                        start_new_session, process_group)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 1551, in _execute_child\n",
            "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
            "                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
            "                             # no special security\n",
            "                             ^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<4 lines>...\n",
            "                             cwd,\n",
            "                             ^^^^\n",
            "                             startupinfo)\n",
            "                             ^^^^^^^^^^^^\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Accuracy: 0.4145927601809955\n",
            "üìä Confusion Matrix:\n",
            " [[ 15   0   1   0   0   2   0   5   0   0   0   0   0   0   0   0   0]\n",
            " [  2  78  45   0   2  26   0  40   3   0   0   4   6   0   0   7   0]\n",
            " [  1   9 465   0  23 111   0 104   2   0   2   8  16   0   6  55   1]\n",
            " [  0   0   4   8   0   1   0  15   0   0   0   0   1   0   0   1   0]\n",
            " [  4   9 124   1 278  94   0 127   3   2   2  15  33   0   7  52   1]\n",
            " [  8   3 135   0  25 376   0 142   2   0   3  15  37   0   3  42   3]\n",
            " [  1   0   6   0   0   5   3   3   0   0   0   0   2   0   0   1   0]\n",
            " [  3   8 123   0  42 110   1 475  10   0   2  25  33   1   3  61   2]\n",
            " [  0   2  29   0  10  36   0  28  62   0   0   5   9   0   0   4   0]\n",
            " [  0   0   7   0   1   3   0   1   0  18   0   0   0   0   2   6   0]\n",
            " [  0   4  31   0  19  24   0  48   3   0  68   0  15   0   0  17   0]\n",
            " [  1   1  12   0   1   6   0  17   0   0   0  22   9   0   0   0   0]\n",
            " [  0   2  48   0  10  47   0  51   0   0   0   8 151   0   1  13   0]\n",
            " [  0   0   8   0   1   3   0   6   0   0   0   2   0   9   0   1   0]\n",
            " [  0   0   1   0   0   1   0   4   0   0   0   0   0   0  10   2   0]\n",
            " [  9  12 128   0  53 150   0 231   6   1   2  25  45   0  13 141   2]\n",
            " [  1   1   4   0   1   6   0  10   0   0   0   0   3   0   0   5  20]]\n",
            "üìÑ Classification Report:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "      Thailand       0.33      0.65      0.44        23\n",
            "       african       0.60      0.37      0.46       213\n",
            "     australia       0.40      0.58      0.47       803\n",
            "       bermuda       0.89      0.27      0.41        30\n",
            "        canada       0.60      0.37      0.46       752\n",
            "       england       0.38      0.47      0.42       794\n",
            "      hongkong       0.75      0.14      0.24        21\n",
            "        indian       0.36      0.53      0.43       899\n",
            "       ireland       0.68      0.34      0.45       185\n",
            "      malaysia       0.86      0.47      0.61        38\n",
            "    newzealand       0.86      0.30      0.44       229\n",
            "   philippines       0.17      0.32      0.22        69\n",
            "      scotland       0.42      0.46      0.44       331\n",
            "     singapore       0.90      0.30      0.45        30\n",
            "southatlandtic       0.22      0.56      0.32        18\n",
            "            us       0.35      0.17      0.23       818\n",
            "         wales       0.69      0.39      0.50        51\n",
            "\n",
            "      accuracy                           0.41      5304\n",
            "     macro avg       0.56      0.39      0.41      5304\n",
            "  weighted avg       0.46      0.41      0.41      5304\n",
            "\n",
            "\n",
            "üîé Training model: SVM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.neighbors import KNeighborsClassifier\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "# from sklearn.ensemble import (\n",
        "#     RandomForestClassifier, GradientBoostingClassifier\n",
        "# )\n",
        "# from sklearn.naive_bayes import GaussianNB\n",
        "# from sklearn.metrics import classification_report\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "# # OPTIONAL: ‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å‡πÉ‡∏ä‡πâ XGBoost\n",
        "# try:\n",
        "#     from xgboost import XGBClassifier\n",
        "#     has_xgb = True\n",
        "# except ImportError:\n",
        "#     has_xgb = False\n",
        "\n",
        "# # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X_full, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# # ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
        "# models = {\n",
        "#     \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "#     \"KNN\": KNeighborsClassifier(),\n",
        "#     \"SVM\": SVC(),\n",
        "#     \"Decision Tree\": DecisionTreeClassifier(),\n",
        "#     \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
        "#     \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "#     \"Naive Bayes\": GaussianNB()\n",
        "# }\n",
        "\n",
        "# if has_xgb:\n",
        "#     models[\"XGBoost\"] = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
        "\n",
        "# # ‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏ó‡∏∏‡∏Å‡∏£‡∏∏‡πà‡∏ô\n",
        "# for name, model in models.items():\n",
        "#     print(f\"\\nüîé Training model: {name}\")\n",
        "#     model.fit(X_train, y_train)\n",
        "#     y_pred = model.predict(X_test)\n",
        "#     print(classification_report(y_test, y_pred, target_names=le_label.classes_))"
      ],
      "metadata": {
        "id": "Wv64iZdAQpYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "accuracies = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    accuracies[name] = acc\n",
        "\n",
        "# ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(accuracies.keys(), accuracies.values(), color='skyblue')\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YvfmN8VaQqgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accent_counts = df[\"accent\"].value_counts()\n",
        "\n",
        "# ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•\n",
        "print(accent_counts)"
      ],
      "metadata": {
        "id": "8wQ8tXCAGdkB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}